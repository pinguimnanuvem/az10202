import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Simulando dados para análise de documentos falsos
# Cada documento tem características numéricas (ex: número de caracteres, proporção de dígitos, etc.)
np.random.seed(42)
num_samples = 1000

# Características: 5 variáveis simuladas (ex: comprimento, proporção de caracteres especiais, etc.)
data = np.random.rand(num_samples, 5)

# Rótulos: 0 (verdadeiro), 1 (falso)
labels = np.random.randint(0, 2, size=num_samples)

# Dividindo os dados em treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)

# Criando o modelo
model = Sequential([
    Dense(32, input_dim=5, activation='relu'),
    Dropout(0.3),
    Dense(16, activation='relu'),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])

# Compilando o modelo
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Treinando o modelo
model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1, validation_split=0.1)

# Avaliando o modelo
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {accuracy:.2f}")

# Relatório de classificação
y_pred = (model.predict(X_test) > 0.5).astype(int)
print(classification_report(y_test, y_pred))

# Função para analisar um novo documento
def analyze_document(features):
    features = np.array(features).reshape(1, -1)
    prediction = model.predict(features)
    return "Falso" if prediction > 0.5 else "Verdadeiro"

# Testando a função
sample_document = [0.5, 0.3, 0.7, 0.2, 0.6]  # Exemplo de características de um documento
result = analyze_document(sample_document)
print(f"O documento analisado é: {result}")
